function net = cnn_init_regression(nb_features, lambda)
%

rng('default');
rng(0);
% input size = 10x20x3
% constant scalar for the random initial network weights. 
f=1/100; 
%net.layers{id}.learningRate = [0, 0]
bias = 0.01;
net.layers = {} ;
%pooling_type = 'max'; % was 'max'
%nb_filters = [32;64;1]; %[64;128;256;7]; [3;32;64;128;1]; [1;32;64;1]
%nb_filters = [nb_features*4;nb_features*4*2;1]; %[360, 720,1]

%nb_filters = [150;50;1]; %[360, 720,1]
%% availPwr has 15 attributes so [90;30;1]
if (nb_features <= 20) % abalone has 8 so [32;64;1] %cpusmall has 12 so [72;144;1] 
    filter1 = round(nb_features .*4); %*4 (*6 for bank8FM)
    filter2 = round(filter1 .*2); %*2
elseif (nb_features <= 26) %parkinson has 26, so [78;39;1]
    filter1 = round(nb_features .*2); %*4 (*6 for bank8FM)
    filter2 = round(filter1 ./ 2); %*2
elseif (nb_features <= 40) % fuelCons has 37 so [74;37;1], maxTorque has 32 so [64;32;1] 
    filter1 = round(nb_features .*2);
    filter2 = round(filter1 ./2);
else  % nb_features> 10 (MSDprediction has 90 so [60;30;1]
    filter1 = round(nb_features .*2/3);
    filter2 = round(filter1 .*2/3);
end
nb_filters = [filter1;filter2;1]; %[360, 720,1]

%% -------------------------------  
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(nb_features,1,1,nb_filters(1), 'single'), zeros(1, nb_filters(1), 'single')}}, ...
                           'biases', bias*ones(1,nb_filters(1),'single'), ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'fc1') ;                 %res(8)
net.layers{end+1} = struct('type', 'relu') ;                %res(9)

%% -------------------------------  
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(1,1,nb_filters(1),nb_filters(2), 'single'), zeros(1, nb_filters(2), 'single')}}, ...
                           'biases', bias*ones(1,nb_filters(2),'single'), ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'fc2') ;                 %res(8)
net.layers{end+1} = struct('type', 'relu') ;    
%% -------------------------------  
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(1,1,nb_filters(2),nb_filters(3), 'single'), zeros(1, nb_filters(3), 'single')}}, ...
                           'biases', bias*ones(1,nb_filters(3),'single'), ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'fc3') ;                 %res(8)
%net.layers{end+1} = struct('type', 'relu') ;                %res(9)

%% -------------------------------  
if(lambda ==4), nnloss_type = 'sigmoidIntegralloss';  %sigmoidIntegralloss
else, nnloss_type = 'euclideanloss'; % all other lambdas 
end

%% -------------------------------
% %add an extra relu for regression type
% if(isequal(opts.prediction_type,'r'))
%     net.layers{end+1} = struct('type', 'relu') ;   %res(12)
% end
% Loss layer
net.layers{end+1} = struct('type', nnloss_type) ; % res(13)

% Visualize the network
vl_simplenn_display(net, 'inputSize', [nb_features 1 1 50])